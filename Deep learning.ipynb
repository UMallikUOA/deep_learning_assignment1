{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# necessary imports\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import urllib.request\n",
    "import tempfile\n",
    "from sklearn.datasets import load_svmlight_file\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Acer\\AppData\\Local\\Temp\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('C:\\\\Users\\\\Acer\\\\AppData\\\\Local\\\\Temp\\\\diabetese',\n",
       " <http.client.HTTPMessage at 0x1562ddb1d48>)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get dataset from csie\n",
    "url = \"https://www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets/binary/diabetes_scale\"\n",
    "# path = \"D:/utsav_university/2024_t3/deep learning/dataset\"\n",
    "# urllib.request.urlretrieve(url,path)\n",
    "\n",
    "temp_path = tempfile.gettempdir()\n",
    "ds_path = f'{temp_path}\\\\diabetese'\n",
    "print(temp_path)\n",
    "urllib.request.urlretrieve(url,ds_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y = load_svmlight_file(ds_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.294118  ,  0.487437  ,  0.180328  , ...,  0.00149028,\n",
       "        -0.53117   , -0.0333333 ],\n",
       "       [-0.882353  , -0.145729  ,  0.0819672 , ..., -0.207153  ,\n",
       "        -0.766866  , -0.666667  ],\n",
       "       [-0.0588235 ,  0.839196  ,  0.0491803 , ..., -0.305514  ,\n",
       "        -0.492741  , -0.633333  ],\n",
       "       ...,\n",
       "       [-0.411765  ,  0.21608   ,  0.180328  , ..., -0.219076  ,\n",
       "        -0.857387  , -0.7       ],\n",
       "       [-0.882353  ,  0.266332  , -0.0163934 , ..., -0.102832  ,\n",
       "        -0.768574  , -0.133333  ],\n",
       "       [-0.882353  , -0.0653266 ,  0.147541  , ..., -0.0938897 ,\n",
       "        -0.797609  , -0.933333  ]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting lables to 0 and 1 as mentioned in the data preprocessing (subsection2.1)\n",
    "def prep_label(y):\n",
    "    return np.where(y == -1, 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = prep_label(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1,\n",
       "       0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0,\n",
       "       1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1,\n",
       "       0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1,\n",
       "       0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
       "       0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0,\n",
       "       0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1,\n",
       "       0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0,\n",
       "       1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0,\n",
       "       0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0,\n",
       "       0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1,\n",
       "       0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1,\n",
       "       0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1,\n",
       "       1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1,\n",
       "       0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1,\n",
       "       1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1,\n",
       "       1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1,\n",
       "       1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1,\n",
       "       1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0,\n",
       "       1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1,\n",
       "       0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1,\n",
       "       0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1,\n",
       "       0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1,\n",
       "       1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1,\n",
       "       1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1,\n",
       "       1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1,\n",
       "       0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0,\n",
       "       1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0,\n",
       "       1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1,\n",
       "       1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1,\n",
       "       1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1,\n",
       "       0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitting the data\n",
    "#using test size as 20% of the data set and setting random_state to my student id: 1898948 as a seed value\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2, random_state=1898948)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a single-layer perceptron in a modular fashion for reusability\n",
    "def percep_mod(lr, af, m):\n",
    "    '''\n",
    "    lr: learning rate\n",
    "    af: activation function\n",
    "    m: momentum\n",
    "    '''\n",
    "    model = Sequential()\n",
    "    # code to implement different activation functions\n",
    "    model.add(Dense(1,input_dim = X_train.shape[1],activation=af))\n",
    "    \n",
    "    # experimenting with different learning rate & momentum values\n",
    "    optimizer = tf.keras.optimizers.SGD(learning_rate=lr, momentum=m)\n",
    "    model.compile(optimizer = optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameter lists\n",
    "lr = [0.1,0.01, 0.001]\n",
    "epoch = [50,100,200]\n",
    "af = ['sigmoid','tanh','relu']\n",
    "m = [0.0,0.2,0.4,0.6,0.8]\n",
    "results = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sigmoid, 0.1, 0.0, 50\n",
      "5/5 [==============================] - 0s 2ms/step\n",
      "sigmoid, 0.1, 0.0, 100\n",
      "5/5 [==============================] - 0s 3ms/step\n",
      "sigmoid, 0.1, 0.0, 200\n",
      "5/5 [==============================] - 0s 1ms/step\n",
      "sigmoid, 0.1, 0.2, 50\n",
      "5/5 [==============================] - 0s 3ms/step\n",
      "sigmoid, 0.1, 0.2, 100\n",
      "5/5 [==============================] - 0s 4ms/step\n",
      "sigmoid, 0.1, 0.2, 200\n",
      "5/5 [==============================] - 0s 8ms/step\n",
      "sigmoid, 0.1, 0.4, 50\n",
      "5/5 [==============================] - 0s 4ms/step\n",
      "sigmoid, 0.1, 0.4, 100\n",
      "5/5 [==============================] - 0s 0s/step\n",
      "sigmoid, 0.1, 0.4, 200\n",
      "5/5 [==============================] - 0s 0s/step\n",
      "sigmoid, 0.1, 0.6, 50\n",
      "5/5 [==============================] - 0s 1ms/step\n",
      "sigmoid, 0.1, 0.6, 100\n",
      "5/5 [==============================] - 0s 0s/step\n",
      "sigmoid, 0.1, 0.6, 200\n",
      "5/5 [==============================] - 0s 4ms/step\n",
      "sigmoid, 0.1, 0.8, 50\n",
      "5/5 [==============================] - 0s 0s/step\n",
      "sigmoid, 0.1, 0.8, 100\n",
      "5/5 [==============================] - 0s 0s/step\n",
      "sigmoid, 0.1, 0.8, 200\n",
      "5/5 [==============================] - 0s 4ms/step\n",
      "sigmoid, 0.01, 0.0, 50\n",
      "5/5 [==============================] - 0s 4ms/step\n",
      "sigmoid, 0.01, 0.0, 100\n",
      "5/5 [==============================] - 0s 0s/step\n",
      "sigmoid, 0.01, 0.0, 200\n",
      "5/5 [==============================] - 0s 4ms/step\n",
      "sigmoid, 0.01, 0.2, 50\n",
      "5/5 [==============================] - 0s 0s/step\n",
      "sigmoid, 0.01, 0.2, 100\n",
      "5/5 [==============================] - 0s 4ms/step\n",
      "sigmoid, 0.01, 0.2, 200\n",
      "5/5 [==============================] - 0s 4ms/step\n",
      "sigmoid, 0.01, 0.4, 50\n",
      "5/5 [==============================] - 0s 0s/step\n",
      "sigmoid, 0.01, 0.4, 100\n",
      "5/5 [==============================] - 0s 0s/step\n",
      "sigmoid, 0.01, 0.4, 200\n",
      "5/5 [==============================] - 0s 4ms/step\n",
      "sigmoid, 0.01, 0.6, 50\n",
      "5/5 [==============================] - 0s 4ms/step\n",
      "sigmoid, 0.01, 0.6, 100\n",
      "5/5 [==============================] - 0s 4ms/step\n",
      "sigmoid, 0.01, 0.6, 200\n",
      "5/5 [==============================] - 0s 1ms/step\n",
      "sigmoid, 0.01, 0.8, 50\n",
      "5/5 [==============================] - 0s 1ms/step\n",
      "sigmoid, 0.01, 0.8, 100\n",
      "5/5 [==============================] - 0s 0s/step\n",
      "sigmoid, 0.01, 0.8, 200\n",
      "5/5 [==============================] - 0s 4ms/step\n",
      "sigmoid, 0.001, 0.0, 50\n",
      "5/5 [==============================] - 0s 4ms/step\n",
      "sigmoid, 0.001, 0.0, 100\n",
      "5/5 [==============================] - 0s 0s/step\n",
      "sigmoid, 0.001, 0.0, 200\n",
      "5/5 [==============================] - 0s 0s/step\n",
      "sigmoid, 0.001, 0.2, 50\n",
      "5/5 [==============================] - 0s 4ms/step\n",
      "sigmoid, 0.001, 0.2, 100\n",
      "5/5 [==============================] - 0s 5ms/step\n",
      "sigmoid, 0.001, 0.2, 200\n",
      "5/5 [==============================] - 0s 3ms/step\n",
      "sigmoid, 0.001, 0.4, 50\n",
      "5/5 [==============================] - 0s 3ms/step\n",
      "sigmoid, 0.001, 0.4, 100\n",
      "5/5 [==============================] - 0s 4ms/step\n",
      "sigmoid, 0.001, 0.4, 200\n",
      "5/5 [==============================] - 0s 2ms/step\n",
      "sigmoid, 0.001, 0.6, 50\n",
      "5/5 [==============================] - 0s 3ms/step\n",
      "sigmoid, 0.001, 0.6, 100\n",
      "5/5 [==============================] - 0s 0s/step\n",
      "sigmoid, 0.001, 0.6, 200\n",
      "5/5 [==============================] - 0s 0s/step\n",
      "sigmoid, 0.001, 0.8, 50\n",
      "5/5 [==============================] - 0s 2ms/step\n",
      "sigmoid, 0.001, 0.8, 100\n",
      "5/5 [==============================] - 0s 0s/step\n",
      "sigmoid, 0.001, 0.8, 200\n",
      "5/5 [==============================] - 0s 4ms/step\n",
      "tanh, 0.1, 0.0, 50\n",
      "5/5 [==============================] - 0s 4ms/step\n",
      "tanh, 0.1, 0.0, 100\n",
      "5/5 [==============================] - 0s 4ms/step\n",
      "tanh, 0.1, 0.0, 200\n",
      "5/5 [==============================] - 0s 0s/step\n",
      "tanh, 0.1, 0.2, 50\n",
      "5/5 [==============================] - 0s 8ms/step\n",
      "tanh, 0.1, 0.2, 100\n",
      "5/5 [==============================] - 0s 4ms/step\n",
      "tanh, 0.1, 0.2, 200\n",
      "5/5 [==============================] - 0s 0s/step\n",
      "tanh, 0.1, 0.4, 50\n",
      "5/5 [==============================] - 0s 2ms/step\n",
      "tanh, 0.1, 0.4, 100\n",
      "5/5 [==============================] - 0s 3ms/step\n",
      "tanh, 0.1, 0.4, 200\n",
      "5/5 [==============================] - 0s 4ms/step\n",
      "tanh, 0.1, 0.6, 50\n",
      "5/5 [==============================] - 0s 4ms/step\n",
      "tanh, 0.1, 0.6, 100\n",
      "5/5 [==============================] - 0s 3ms/step\n",
      "tanh, 0.1, 0.6, 200\n",
      "5/5 [==============================] - 0s 2ms/step\n",
      "tanh, 0.1, 0.8, 50\n",
      "5/5 [==============================] - 0s 0s/step\n",
      "tanh, 0.1, 0.8, 100\n",
      "5/5 [==============================] - 0s 3ms/step\n",
      "tanh, 0.1, 0.8, 200\n",
      "5/5 [==============================] - 0s 0s/step\n",
      "tanh, 0.01, 0.0, 50\n",
      "5/5 [==============================] - 0s 4ms/step\n",
      "tanh, 0.01, 0.0, 100\n",
      "5/5 [==============================] - 0s 4ms/step\n",
      "tanh, 0.01, 0.0, 200\n",
      "5/5 [==============================] - 0s 4ms/step\n",
      "tanh, 0.01, 0.2, 50\n",
      "5/5 [==============================] - 0s 0s/step\n",
      "tanh, 0.01, 0.2, 100\n",
      "5/5 [==============================] - 0s 0s/step\n",
      "tanh, 0.01, 0.2, 200\n",
      "5/5 [==============================] - 0s 4ms/step\n",
      "tanh, 0.01, 0.4, 50\n",
      "5/5 [==============================] - 0s 0s/step\n",
      "tanh, 0.01, 0.4, 100\n",
      "5/5 [==============================] - 0s 4ms/step\n",
      "tanh, 0.01, 0.4, 200\n",
      "5/5 [==============================] - 0s 0s/step\n",
      "tanh, 0.01, 0.6, 50\n",
      "5/5 [==============================] - 0s 0s/step\n",
      "tanh, 0.01, 0.6, 100\n",
      "5/5 [==============================] - 0s 4ms/step\n",
      "tanh, 0.01, 0.6, 200\n",
      "5/5 [==============================] - 0s 0s/step\n",
      "tanh, 0.01, 0.8, 50\n",
      "5/5 [==============================] - 0s 4ms/step\n",
      "tanh, 0.01, 0.8, 100\n",
      "5/5 [==============================] - 0s 0s/step\n",
      "tanh, 0.01, 0.8, 200\n",
      "5/5 [==============================] - 0s 4ms/step\n",
      "tanh, 0.001, 0.0, 50\n",
      "5/5 [==============================] - 0s 0s/step\n",
      "tanh, 0.001, 0.0, 100\n",
      "5/5 [==============================] - 0s 0s/step\n",
      "tanh, 0.001, 0.0, 200\n",
      "5/5 [==============================] - 0s 4ms/step\n",
      "tanh, 0.001, 0.2, 50\n",
      "5/5 [==============================] - 0s 0s/step\n",
      "tanh, 0.001, 0.2, 100\n",
      "5/5 [==============================] - 0s 4ms/step\n",
      "tanh, 0.001, 0.2, 200\n",
      "5/5 [==============================] - 0s 0s/step\n",
      "tanh, 0.001, 0.4, 50\n",
      "5/5 [==============================] - 0s 0s/step\n",
      "tanh, 0.001, 0.4, 100\n",
      "5/5 [==============================] - 0s 0s/step\n",
      "tanh, 0.001, 0.4, 200\n",
      "5/5 [==============================] - 0s 0s/step\n",
      "tanh, 0.001, 0.6, 50\n",
      "5/5 [==============================] - 0s 3ms/step\n",
      "tanh, 0.001, 0.6, 100\n",
      "5/5 [==============================] - 0s 0s/step\n",
      "tanh, 0.001, 0.6, 200\n",
      "5/5 [==============================] - 0s 2ms/step\n",
      "tanh, 0.001, 0.8, 50\n",
      "5/5 [==============================] - 0s 0s/step\n",
      "tanh, 0.001, 0.8, 100\n",
      "5/5 [==============================] - 0s 4ms/step\n",
      "tanh, 0.001, 0.8, 200\n",
      "5/5 [==============================] - 0s 4ms/step\n",
      "relu, 0.1, 0.0, 50\n",
      "5/5 [==============================] - 0s 4ms/step\n",
      "relu, 0.1, 0.0, 100\n",
      "5/5 [==============================] - 0s 0s/step\n",
      "relu, 0.1, 0.0, 200\n",
      "5/5 [==============================] - 0s 0s/step\n",
      "relu, 0.1, 0.2, 50\n",
      "5/5 [==============================] - 0s 0s/step\n",
      "relu, 0.1, 0.2, 100\n",
      "5/5 [==============================] - 0s 0s/step\n",
      "relu, 0.1, 0.2, 200\n",
      "5/5 [==============================] - 0s 4ms/step\n",
      "relu, 0.1, 0.4, 50\n",
      "5/5 [==============================] - 0s 8ms/step\n",
      "relu, 0.1, 0.4, 100\n",
      "5/5 [==============================] - 0s 0s/step\n",
      "relu, 0.1, 0.4, 200\n",
      "5/5 [==============================] - 0s 5ms/step\n",
      "relu, 0.1, 0.6, 50\n",
      "5/5 [==============================] - 0s 0s/step\n",
      "relu, 0.1, 0.6, 100\n",
      "5/5 [==============================] - 0s 4ms/step\n",
      "relu, 0.1, 0.6, 200\n",
      "5/5 [==============================] - 0s 0s/step\n",
      "relu, 0.1, 0.8, 50\n",
      "5/5 [==============================] - 0s 1ms/step\n",
      "relu, 0.1, 0.8, 100\n",
      "5/5 [==============================] - 0s 4ms/step\n",
      "relu, 0.1, 0.8, 200\n",
      "5/5 [==============================] - 0s 12ms/step\n",
      "relu, 0.01, 0.0, 50\n",
      "5/5 [==============================] - 0s 0s/step\n",
      "relu, 0.01, 0.0, 100\n",
      "5/5 [==============================] - 0s 0s/step\n",
      "relu, 0.01, 0.0, 200\n",
      "5/5 [==============================] - 0s 0s/step\n",
      "relu, 0.01, 0.2, 50\n",
      "5/5 [==============================] - 0s 4ms/step\n",
      "relu, 0.01, 0.2, 100\n",
      "5/5 [==============================] - 0s 0s/step\n",
      "relu, 0.01, 0.2, 200\n",
      "5/5 [==============================] - 0s 4ms/step\n",
      "relu, 0.01, 0.4, 50\n",
      "5/5 [==============================] - 0s 0s/step\n",
      "relu, 0.01, 0.4, 100\n",
      "5/5 [==============================] - 0s 0s/step\n",
      "relu, 0.01, 0.4, 200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 512us/step\n",
      "relu, 0.01, 0.6, 50\n",
      "5/5 [==============================] - 0s 4ms/step\n",
      "relu, 0.01, 0.6, 100\n",
      "5/5 [==============================] - 0s 880us/step\n",
      "relu, 0.01, 0.6, 200\n",
      "5/5 [==============================] - 0s 4ms/step\n",
      "relu, 0.01, 0.8, 50\n",
      "5/5 [==============================] - 0s 4ms/step\n",
      "relu, 0.01, 0.8, 100\n",
      "5/5 [==============================] - 0s 4ms/step\n",
      "relu, 0.01, 0.8, 200\n",
      "5/5 [==============================] - 0s 4ms/step\n",
      "relu, 0.001, 0.0, 50\n",
      "5/5 [==============================] - 0s 4ms/step\n",
      "relu, 0.001, 0.0, 100\n",
      "5/5 [==============================] - 0s 1ms/step\n",
      "relu, 0.001, 0.0, 200\n",
      "5/5 [==============================] - 0s 13ms/step\n",
      "relu, 0.001, 0.2, 50\n",
      "5/5 [==============================] - 0s 0s/step\n",
      "relu, 0.001, 0.2, 100\n",
      "5/5 [==============================] - 0s 0s/step\n",
      "relu, 0.001, 0.2, 200\n",
      "5/5 [==============================] - 0s 0s/step\n",
      "relu, 0.001, 0.4, 50\n",
      "5/5 [==============================] - 0s 0s/step\n",
      "relu, 0.001, 0.4, 100\n",
      "5/5 [==============================] - 0s 4ms/step\n",
      "relu, 0.001, 0.4, 200\n",
      "5/5 [==============================] - 0s 1ms/step\n",
      "relu, 0.001, 0.6, 50\n",
      "5/5 [==============================] - 0s 244us/step\n",
      "relu, 0.001, 0.6, 100\n",
      "5/5 [==============================] - 0s 4ms/step\n",
      "relu, 0.001, 0.6, 200\n",
      "5/5 [==============================] - 0s 0s/step\n",
      "relu, 0.001, 0.8, 50\n",
      "5/5 [==============================] - 0s 0s/step\n",
      "relu, 0.001, 0.8, 100\n",
      "5/5 [==============================] - 0s 2ms/step\n",
      "relu, 0.001, 0.8, 200\n",
      "5/5 [==============================] - 0s 0s/step\n"
     ]
    }
   ],
   "source": [
    "# looping through the various hyperparameters\n",
    "for func in af:\n",
    "    for rate in lr:\n",
    "        for mo in m:\n",
    "            for e in epoch:\n",
    "                model = percep_mod(lr=rate,af=func,m = mo)\n",
    "#                 print(f'{lr} {e}')\n",
    "                print(f'{func}, {rate}, {mo}, {e}')\n",
    "                # training\n",
    "                history = model.fit(X_train, y_train, epochs =e, validation_data=(X_test, y_test), verbose=0)\n",
    "#                 print(history)\n",
    "                # predicting / testing\n",
    "                y_pred = (model.predict(X_test)>0.5).astype(\"int32\")\n",
    "#                 print(y_pred)\n",
    "#             got the warning UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. \n",
    "#             Use `zero_division` parameter to control this behavior.\n",
    "#                 so will use parameter zero_division = 1 in precision_score\n",
    "                accuracy,precision,recall,f1Score=accuracy_score(y_test,y_pred),precision_score(y_test,y_pred,zero_division=1),recall_score(y_test,y_pred),f1_score(y_test,y_pred)\n",
    "                results.append((func,rate,mo,e,accuracy,precision,recall,f1Score))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Activation Function:sigmoid, Learning Rate: 0.1, Momentum:0.0, Epoch:50, Accuracy:0.7922077922077922, Precision:0.8141592920353983, Recall:0.8932038834951457, F1:0.851851851851852\n",
      "Activation Function:sigmoid, Learning Rate: 0.1, Momentum:0.0, Epoch:100, Accuracy:0.7922077922077922, Precision:0.808695652173913, Recall:0.9029126213592233, F1:0.8532110091743119\n",
      "Activation Function:sigmoid, Learning Rate: 0.1, Momentum:0.0, Epoch:200, Accuracy:0.8116883116883117, Precision:0.8303571428571429, Recall:0.9029126213592233, F1:0.8651162790697675\n",
      "Activation Function:sigmoid, Learning Rate: 0.1, Momentum:0.2, Epoch:50, Accuracy:0.8116883116883117, Precision:0.8135593220338984, Recall:0.9320388349514563, F1:0.8687782805429866\n",
      "Activation Function:sigmoid, Learning Rate: 0.1, Momentum:0.2, Epoch:100, Accuracy:0.7987012987012987, Precision:0.8103448275862069, Recall:0.912621359223301, F1:0.8584474885844748\n",
      "Activation Function:sigmoid, Learning Rate: 0.1, Momentum:0.2, Epoch:200, Accuracy:0.7987012987012987, Precision:0.8103448275862069, Recall:0.912621359223301, F1:0.8584474885844748\n",
      "Activation Function:sigmoid, Learning Rate: 0.1, Momentum:0.4, Epoch:50, Accuracy:0.7987012987012987, Precision:0.8050847457627118, Recall:0.9223300970873787, F1:0.8597285067873303\n",
      "Activation Function:sigmoid, Learning Rate: 0.1, Momentum:0.4, Epoch:100, Accuracy:0.8051948051948052, Precision:0.8173913043478261, Recall:0.912621359223301, F1:0.8623853211009174\n",
      "Activation Function:sigmoid, Learning Rate: 0.1, Momentum:0.4, Epoch:200, Accuracy:0.8051948051948052, Precision:0.8173913043478261, Recall:0.912621359223301, F1:0.8623853211009174\n",
      "Activation Function:sigmoid, Learning Rate: 0.1, Momentum:0.6, Epoch:50, Accuracy:0.7987012987012987, Precision:0.8103448275862069, Recall:0.912621359223301, F1:0.8584474885844748\n",
      "Activation Function:sigmoid, Learning Rate: 0.1, Momentum:0.6, Epoch:100, Accuracy:0.7987012987012987, Precision:0.8103448275862069, Recall:0.912621359223301, F1:0.8584474885844748\n",
      "Activation Function:sigmoid, Learning Rate: 0.1, Momentum:0.6, Epoch:200, Accuracy:0.8051948051948052, Precision:0.8173913043478261, Recall:0.912621359223301, F1:0.8623853211009174\n",
      "Activation Function:sigmoid, Learning Rate: 0.1, Momentum:0.8, Epoch:50, Accuracy:0.8181818181818182, Precision:0.8378378378378378, Recall:0.9029126213592233, F1:0.869158878504673\n",
      "Activation Function:sigmoid, Learning Rate: 0.1, Momentum:0.8, Epoch:100, Accuracy:0.8116883116883117, Precision:0.8303571428571429, Recall:0.9029126213592233, F1:0.8651162790697675\n",
      "Activation Function:sigmoid, Learning Rate: 0.1, Momentum:0.8, Epoch:200, Accuracy:0.8051948051948052, Precision:0.8348623853211009, Recall:0.883495145631068, F1:0.8584905660377358\n",
      "Activation Function:sigmoid, Learning Rate: 0.01, Momentum:0.0, Epoch:50, Accuracy:0.6753246753246753, Precision:0.673202614379085, Recall:1.0, F1:0.8046875\n",
      "Activation Function:sigmoid, Learning Rate: 0.01, Momentum:0.0, Epoch:100, Accuracy:0.7857142857142857, Precision:0.7692307692307693, Recall:0.970873786407767, F1:0.8583690987124465\n",
      "Activation Function:sigmoid, Learning Rate: 0.01, Momentum:0.0, Epoch:200, Accuracy:0.7467532467532467, Precision:0.753968253968254, Recall:0.9223300970873787, F1:0.8296943231441049\n",
      "Activation Function:sigmoid, Learning Rate: 0.01, Momentum:0.2, Epoch:50, Accuracy:0.6688311688311688, Precision:0.6710526315789473, Recall:0.9902912621359223, F1:0.8\n",
      "Activation Function:sigmoid, Learning Rate: 0.01, Momentum:0.2, Epoch:100, Accuracy:0.7467532467532467, Precision:0.7318840579710145, Recall:0.9805825242718447, F1:0.8381742738589211\n",
      "Activation Function:sigmoid, Learning Rate: 0.01, Momentum:0.2, Epoch:200, Accuracy:0.7922077922077922, Precision:0.7933884297520661, Recall:0.9320388349514563, F1:0.8571428571428571\n",
      "Activation Function:sigmoid, Learning Rate: 0.01, Momentum:0.4, Epoch:50, Accuracy:0.7337662337662337, Precision:0.7313432835820896, Recall:0.9514563106796117, F1:0.8270042194092827\n",
      "Activation Function:sigmoid, Learning Rate: 0.01, Momentum:0.4, Epoch:100, Accuracy:0.7922077922077922, Precision:0.7795275590551181, Recall:0.9611650485436893, F1:0.8608695652173913\n",
      "Activation Function:sigmoid, Learning Rate: 0.01, Momentum:0.4, Epoch:200, Accuracy:0.7727272727272727, Precision:0.788135593220339, Recall:0.9029126213592233, F1:0.8416289592760181\n",
      "Activation Function:sigmoid, Learning Rate: 0.01, Momentum:0.6, Epoch:50, Accuracy:0.7532467532467533, Precision:0.751937984496124, Recall:0.941747572815534, F1:0.8362068965517242\n",
      "Activation Function:sigmoid, Learning Rate: 0.01, Momentum:0.6, Epoch:100, Accuracy:0.7922077922077922, Precision:0.7886178861788617, Recall:0.941747572815534, F1:0.8584070796460177\n",
      "Activation Function:sigmoid, Learning Rate: 0.01, Momentum:0.6, Epoch:200, Accuracy:0.8051948051948052, Precision:0.8067226890756303, Recall:0.9320388349514563, F1:0.8648648648648649\n",
      "Activation Function:sigmoid, Learning Rate: 0.01, Momentum:0.8, Epoch:50, Accuracy:0.7857142857142857, Precision:0.7868852459016393, Recall:0.9320388349514563, F1:0.8533333333333334\n",
      "Activation Function:sigmoid, Learning Rate: 0.01, Momentum:0.8, Epoch:100, Accuracy:0.8051948051948052, Precision:0.8067226890756303, Recall:0.9320388349514563, F1:0.8648648648648649\n",
      "Activation Function:sigmoid, Learning Rate: 0.01, Momentum:0.8, Epoch:200, Accuracy:0.7987012987012987, Precision:0.8103448275862069, Recall:0.912621359223301, F1:0.8584474885844748\n",
      "Activation Function:sigmoid, Learning Rate: 0.001, Momentum:0.0, Epoch:50, Accuracy:0.5, Precision:0.7321428571428571, Recall:0.39805825242718446, F1:0.5157232704402516\n",
      "Activation Function:sigmoid, Learning Rate: 0.001, Momentum:0.0, Epoch:100, Accuracy:0.7142857142857143, Precision:0.7062937062937062, Recall:0.9805825242718447, F1:0.8211382113821137\n",
      "Activation Function:sigmoid, Learning Rate: 0.001, Momentum:0.0, Epoch:200, Accuracy:0.6623376623376623, Precision:0.673469387755102, Recall:0.9611650485436893, F1:0.7919999999999999\n",
      "Activation Function:sigmoid, Learning Rate: 0.001, Momentum:0.2, Epoch:50, Accuracy:0.7207792207792207, Precision:0.7112676056338029, Recall:0.9805825242718447, F1:0.8244897959183672\n",
      "Activation Function:sigmoid, Learning Rate: 0.001, Momentum:0.2, Epoch:100, Accuracy:0.7012987012987013, Precision:0.696551724137931, Recall:0.9805825242718447, F1:0.814516129032258\n",
      "Activation Function:sigmoid, Learning Rate: 0.001, Momentum:0.2, Epoch:200, Accuracy:0.7207792207792207, Precision:0.7238805970149254, Recall:0.941747572815534, F1:0.8185654008438819\n",
      "Activation Function:sigmoid, Learning Rate: 0.001, Momentum:0.4, Epoch:50, Accuracy:0.6753246753246753, Precision:0.6992481203007519, Recall:0.9029126213592233, F1:0.7881355932203391\n",
      "Activation Function:sigmoid, Learning Rate: 0.001, Momentum:0.4, Epoch:100, Accuracy:0.7077922077922078, Precision:0.7196969696969697, Recall:0.9223300970873787, F1:0.8085106382978723\n",
      "Activation Function:sigmoid, Learning Rate: 0.001, Momentum:0.4, Epoch:200, Accuracy:0.6688311688311688, Precision:0.678082191780822, Recall:0.9611650485436893, F1:0.7951807228915664\n",
      "Activation Function:sigmoid, Learning Rate: 0.001, Momentum:0.6, Epoch:50, Accuracy:0.6818181818181818, Precision:0.7014925373134329, Recall:0.912621359223301, F1:0.7932489451476794\n",
      "Activation Function:sigmoid, Learning Rate: 0.001, Momentum:0.6, Epoch:100, Accuracy:0.6818181818181818, Precision:0.684931506849315, Recall:0.970873786407767, F1:0.8032128514056225\n",
      "Activation Function:sigmoid, Learning Rate: 0.001, Momentum:0.6, Epoch:200, Accuracy:0.7207792207792207, Precision:0.7142857142857143, Recall:0.970873786407767, F1:0.8230452674897119\n",
      "Activation Function:sigmoid, Learning Rate: 0.001, Momentum:0.8, Epoch:50, Accuracy:0.7597402597402597, Precision:0.7426470588235294, Recall:0.9805825242718447, F1:0.8451882845188284\n",
      "Activation Function:sigmoid, Learning Rate: 0.001, Momentum:0.8, Epoch:100, Accuracy:0.7467532467532467, Precision:0.7285714285714285, Recall:0.9902912621359223, F1:0.8395061728395061\n",
      "Activation Function:sigmoid, Learning Rate: 0.001, Momentum:0.8, Epoch:200, Accuracy:0.7272727272727273, Precision:0.725925925925926, Recall:0.9514563106796117, F1:0.823529411764706\n",
      "Activation Function:tanh, Learning Rate: 0.1, Momentum:0.0, Epoch:50, Accuracy:0.8051948051948052, Precision:0.8067226890756303, Recall:0.9320388349514563, F1:0.8648648648648649\n",
      "Activation Function:tanh, Learning Rate: 0.1, Momentum:0.0, Epoch:100, Accuracy:0.6688311688311688, Precision:0.6688311688311688, Recall:1.0, F1:0.801556420233463\n",
      "Activation Function:tanh, Learning Rate: 0.1, Momentum:0.0, Epoch:200, Accuracy:0.6688311688311688, Precision:0.6688311688311688, Recall:1.0, F1:0.801556420233463\n",
      "Activation Function:tanh, Learning Rate: 0.1, Momentum:0.2, Epoch:50, Accuracy:0.6688311688311688, Precision:0.6688311688311688, Recall:1.0, F1:0.801556420233463\n",
      "Activation Function:tanh, Learning Rate: 0.1, Momentum:0.2, Epoch:100, Accuracy:0.7857142857142857, Precision:0.782258064516129, Recall:0.941747572815534, F1:0.8546255506607929\n",
      "Activation Function:tanh, Learning Rate: 0.1, Momentum:0.2, Epoch:200, Accuracy:0.6688311688311688, Precision:0.6688311688311688, Recall:1.0, F1:0.801556420233463\n",
      "Activation Function:tanh, Learning Rate: 0.1, Momentum:0.4, Epoch:50, Accuracy:0.6688311688311688, Precision:0.6688311688311688, Recall:1.0, F1:0.801556420233463\n",
      "Activation Function:tanh, Learning Rate: 0.1, Momentum:0.4, Epoch:100, Accuracy:0.8051948051948052, Precision:0.811965811965812, Recall:0.9223300970873787, F1:0.8636363636363636\n",
      "Activation Function:tanh, Learning Rate: 0.1, Momentum:0.4, Epoch:200, Accuracy:0.6688311688311688, Precision:0.6688311688311688, Recall:1.0, F1:0.801556420233463\n",
      "Activation Function:tanh, Learning Rate: 0.1, Momentum:0.6, Epoch:50, Accuracy:0.6753246753246753, Precision:0.6827586206896552, Recall:0.9611650485436893, F1:0.7983870967741936\n",
      "Activation Function:tanh, Learning Rate: 0.1, Momentum:0.6, Epoch:100, Accuracy:0.6688311688311688, Precision:0.6688311688311688, Recall:1.0, F1:0.801556420233463\n",
      "Activation Function:tanh, Learning Rate: 0.1, Momentum:0.6, Epoch:200, Accuracy:0.6688311688311688, Precision:0.6688311688311688, Recall:1.0, F1:0.801556420233463\n",
      "Activation Function:tanh, Learning Rate: 0.1, Momentum:0.8, Epoch:50, Accuracy:0.6688311688311688, Precision:0.6688311688311688, Recall:1.0, F1:0.801556420233463\n",
      "Activation Function:tanh, Learning Rate: 0.1, Momentum:0.8, Epoch:100, Accuracy:0.6688311688311688, Precision:0.6688311688311688, Recall:1.0, F1:0.801556420233463\n",
      "Activation Function:tanh, Learning Rate: 0.1, Momentum:0.8, Epoch:200, Accuracy:0.6688311688311688, Precision:0.6688311688311688, Recall:1.0, F1:0.801556420233463\n",
      "Activation Function:tanh, Learning Rate: 0.01, Momentum:0.0, Epoch:50, Accuracy:0.8116883116883117, Precision:0.7983870967741935, Recall:0.9611650485436893, F1:0.8722466960352422\n",
      "Activation Function:tanh, Learning Rate: 0.01, Momentum:0.0, Epoch:100, Accuracy:0.33116883116883117, Precision:1.0, Recall:0.0, F1:0.0\n",
      "Activation Function:tanh, Learning Rate: 0.01, Momentum:0.0, Epoch:200, Accuracy:0.7987012987012987, Precision:0.7903225806451613, Recall:0.9514563106796117, F1:0.8634361233480176\n",
      "Activation Function:tanh, Learning Rate: 0.01, Momentum:0.2, Epoch:50, Accuracy:0.33116883116883117, Precision:1.0, Recall:0.0, F1:0.0\n",
      "Activation Function:tanh, Learning Rate: 0.01, Momentum:0.2, Epoch:100, Accuracy:0.7792207792207793, Precision:0.776, Recall:0.941747572815534, F1:0.8508771929824562\n",
      "Activation Function:tanh, Learning Rate: 0.01, Momentum:0.2, Epoch:200, Accuracy:0.7922077922077922, Precision:0.7886178861788617, Recall:0.941747572815534, F1:0.8584070796460177\n",
      "Activation Function:tanh, Learning Rate: 0.01, Momentum:0.4, Epoch:50, Accuracy:0.8051948051948052, Precision:0.8067226890756303, Recall:0.9320388349514563, F1:0.8648648648648649\n",
      "Activation Function:tanh, Learning Rate: 0.01, Momentum:0.4, Epoch:100, Accuracy:0.8051948051948052, Precision:0.8173913043478261, Recall:0.912621359223301, F1:0.8623853211009174\n",
      "Activation Function:tanh, Learning Rate: 0.01, Momentum:0.4, Epoch:200, Accuracy:0.7922077922077922, Precision:0.7983193277310925, Recall:0.9223300970873787, F1:0.8558558558558559\n",
      "Activation Function:tanh, Learning Rate: 0.01, Momentum:0.6, Epoch:50, Accuracy:0.7727272727272727, Precision:0.7698412698412699, Recall:0.941747572815534, F1:0.8471615720524018\n",
      "Activation Function:tanh, Learning Rate: 0.01, Momentum:0.6, Epoch:100, Accuracy:0.7922077922077922, Precision:0.808695652173913, Recall:0.9029126213592233, F1:0.8532110091743119\n",
      "Activation Function:tanh, Learning Rate: 0.01, Momentum:0.6, Epoch:200, Accuracy:0.8116883116883117, Precision:0.8135593220338984, Recall:0.9320388349514563, F1:0.8687782805429866\n",
      "Activation Function:tanh, Learning Rate: 0.01, Momentum:0.8, Epoch:50, Accuracy:0.7727272727272727, Precision:0.7833333333333333, Recall:0.912621359223301, F1:0.8430493273542601\n",
      "Activation Function:tanh, Learning Rate: 0.01, Momentum:0.8, Epoch:100, Accuracy:0.7727272727272727, Precision:0.7741935483870968, Recall:0.9320388349514563, F1:0.8458149779735683\n",
      "Activation Function:tanh, Learning Rate: 0.01, Momentum:0.8, Epoch:200, Accuracy:0.7337662337662337, Precision:0.7421875, Recall:0.9223300970873787, F1:0.8225108225108225\n",
      "Activation Function:tanh, Learning Rate: 0.001, Momentum:0.0, Epoch:50, Accuracy:0.7142857142857143, Precision:0.7092198581560284, Recall:0.970873786407767, F1:0.819672131147541\n",
      "Activation Function:tanh, Learning Rate: 0.001, Momentum:0.0, Epoch:100, Accuracy:0.6818181818181818, Precision:0.6956521739130435, Recall:0.9320388349514563, F1:0.7966804979253111\n",
      "Activation Function:tanh, Learning Rate: 0.001, Momentum:0.0, Epoch:200, Accuracy:0.7207792207792207, Precision:0.7142857142857143, Recall:0.970873786407767, F1:0.8230452674897119\n",
      "Activation Function:tanh, Learning Rate: 0.001, Momentum:0.2, Epoch:50, Accuracy:0.7272727272727273, Precision:0.732824427480916, Recall:0.9320388349514563, F1:0.8205128205128206\n",
      "Activation Function:tanh, Learning Rate: 0.001, Momentum:0.2, Epoch:100, Accuracy:0.6818181818181818, Precision:0.7076923076923077, Recall:0.8932038834951457, F1:0.7896995708154506\n",
      "Activation Function:tanh, Learning Rate: 0.001, Momentum:0.2, Epoch:200, Accuracy:0.7337662337662337, Precision:0.746031746031746, Recall:0.912621359223301, F1:0.8209606986899564\n",
      "Activation Function:tanh, Learning Rate: 0.001, Momentum:0.4, Epoch:50, Accuracy:0.6623376623376623, Precision:0.6976744186046512, Recall:0.8737864077669902, F1:0.7758620689655172\n",
      "Activation Function:tanh, Learning Rate: 0.001, Momentum:0.4, Epoch:100, Accuracy:0.7532467532467533, Precision:0.7559055118110236, Recall:0.9320388349514563, F1:0.8347826086956522\n",
      "Activation Function:tanh, Learning Rate: 0.001, Momentum:0.4, Epoch:200, Accuracy:0.7402597402597403, Precision:0.7560975609756098, Recall:0.9029126213592233, F1:0.8230088495575221\n",
      "Activation Function:tanh, Learning Rate: 0.001, Momentum:0.6, Epoch:50, Accuracy:0.7077922077922078, Precision:0.7196969696969697, Recall:0.9223300970873787, F1:0.8085106382978723\n",
      "Activation Function:tanh, Learning Rate: 0.001, Momentum:0.6, Epoch:100, Accuracy:0.7142857142857143, Precision:0.7218045112781954, Recall:0.9320388349514563, F1:0.8135593220338982\n",
      "Activation Function:tanh, Learning Rate: 0.001, Momentum:0.6, Epoch:200, Accuracy:0.7662337662337663, Precision:0.7723577235772358, Recall:0.9223300970873787, F1:0.8407079646017699\n",
      "Activation Function:tanh, Learning Rate: 0.001, Momentum:0.8, Epoch:50, Accuracy:0.7272727272727273, Precision:0.7293233082706767, Recall:0.941747572815534, F1:0.8220338983050848\n",
      "Activation Function:tanh, Learning Rate: 0.001, Momentum:0.8, Epoch:100, Accuracy:0.7662337662337663, Precision:0.768, Recall:0.9320388349514563, F1:0.8421052631578948\n",
      "Activation Function:tanh, Learning Rate: 0.001, Momentum:0.8, Epoch:200, Accuracy:0.7922077922077922, Precision:0.7886178861788617, Recall:0.941747572815534, F1:0.8584070796460177\n",
      "Activation Function:relu, Learning Rate: 0.1, Momentum:0.0, Epoch:50, Accuracy:0.6688311688311688, Precision:0.6688311688311688, Recall:1.0, F1:0.801556420233463\n",
      "Activation Function:relu, Learning Rate: 0.1, Momentum:0.0, Epoch:100, Accuracy:0.6753246753246753, Precision:0.673202614379085, Recall:1.0, F1:0.8046875\n",
      "Activation Function:relu, Learning Rate: 0.1, Momentum:0.0, Epoch:200, Accuracy:0.33116883116883117, Precision:1.0, Recall:0.0, F1:0.0\n",
      "Activation Function:relu, Learning Rate: 0.1, Momentum:0.2, Epoch:50, Accuracy:0.33116883116883117, Precision:1.0, Recall:0.0, F1:0.0\n",
      "Activation Function:relu, Learning Rate: 0.1, Momentum:0.2, Epoch:100, Accuracy:0.33116883116883117, Precision:1.0, Recall:0.0, F1:0.0\n",
      "Activation Function:relu, Learning Rate: 0.1, Momentum:0.2, Epoch:200, Accuracy:0.6753246753246753, Precision:0.673202614379085, Recall:1.0, F1:0.8046875\n",
      "Activation Function:relu, Learning Rate: 0.1, Momentum:0.4, Epoch:50, Accuracy:0.6688311688311688, Precision:0.6688311688311688, Recall:1.0, F1:0.801556420233463\n",
      "Activation Function:relu, Learning Rate: 0.1, Momentum:0.4, Epoch:100, Accuracy:0.33766233766233766, Precision:1.0, Recall:0.009708737864077669, F1:0.01923076923076923\n",
      "Activation Function:relu, Learning Rate: 0.1, Momentum:0.4, Epoch:200, Accuracy:0.33116883116883117, Precision:1.0, Recall:0.0, F1:0.0\n",
      "Activation Function:relu, Learning Rate: 0.1, Momentum:0.6, Epoch:50, Accuracy:0.33116883116883117, Precision:1.0, Recall:0.0, F1:0.0\n",
      "Activation Function:relu, Learning Rate: 0.1, Momentum:0.6, Epoch:100, Accuracy:0.6688311688311688, Precision:0.6688311688311688, Recall:1.0, F1:0.801556420233463\n",
      "Activation Function:relu, Learning Rate: 0.1, Momentum:0.6, Epoch:200, Accuracy:0.6688311688311688, Precision:0.6688311688311688, Recall:1.0, F1:0.801556420233463\n",
      "Activation Function:relu, Learning Rate: 0.1, Momentum:0.8, Epoch:50, Accuracy:0.6688311688311688, Precision:0.6688311688311688, Recall:1.0, F1:0.801556420233463\n",
      "Activation Function:relu, Learning Rate: 0.1, Momentum:0.8, Epoch:100, Accuracy:0.6688311688311688, Precision:0.6688311688311688, Recall:1.0, F1:0.801556420233463\n",
      "Activation Function:relu, Learning Rate: 0.1, Momentum:0.8, Epoch:200, Accuracy:0.6753246753246753, Precision:0.673202614379085, Recall:1.0, F1:0.8046875\n",
      "Activation Function:relu, Learning Rate: 0.01, Momentum:0.0, Epoch:50, Accuracy:0.7922077922077922, Precision:0.8198198198198198, Recall:0.883495145631068, F1:0.850467289719626\n",
      "Activation Function:relu, Learning Rate: 0.01, Momentum:0.0, Epoch:100, Accuracy:0.33116883116883117, Precision:1.0, Recall:0.0, F1:0.0\n",
      "Activation Function:relu, Learning Rate: 0.01, Momentum:0.0, Epoch:200, Accuracy:0.33116883116883117, Precision:1.0, Recall:0.0, F1:0.0\n",
      "Activation Function:relu, Learning Rate: 0.01, Momentum:0.2, Epoch:50, Accuracy:0.6688311688311688, Precision:0.6688311688311688, Recall:1.0, F1:0.801556420233463\n",
      "Activation Function:relu, Learning Rate: 0.01, Momentum:0.2, Epoch:100, Accuracy:0.33116883116883117, Precision:1.0, Recall:0.0, F1:0.0\n",
      "Activation Function:relu, Learning Rate: 0.01, Momentum:0.2, Epoch:200, Accuracy:0.33116883116883117, Precision:1.0, Recall:0.0, F1:0.0\n",
      "Activation Function:relu, Learning Rate: 0.01, Momentum:0.4, Epoch:50, Accuracy:0.7337662337662337, Precision:0.7583333333333333, Recall:0.883495145631068, F1:0.8161434977578474\n",
      "Activation Function:relu, Learning Rate: 0.01, Momentum:0.4, Epoch:100, Accuracy:0.33116883116883117, Precision:1.0, Recall:0.0, F1:0.0\n",
      "Activation Function:relu, Learning Rate: 0.01, Momentum:0.4, Epoch:200, Accuracy:0.33116883116883117, Precision:1.0, Recall:0.0, F1:0.0\n",
      "Activation Function:relu, Learning Rate: 0.01, Momentum:0.6, Epoch:50, Accuracy:0.33116883116883117, Precision:1.0, Recall:0.0, F1:0.0\n",
      "Activation Function:relu, Learning Rate: 0.01, Momentum:0.6, Epoch:100, Accuracy:0.33116883116883117, Precision:1.0, Recall:0.0, F1:0.0\n",
      "Activation Function:relu, Learning Rate: 0.01, Momentum:0.6, Epoch:200, Accuracy:0.6688311688311688, Precision:0.6688311688311688, Recall:1.0, F1:0.801556420233463\n",
      "Activation Function:relu, Learning Rate: 0.01, Momentum:0.8, Epoch:50, Accuracy:0.33116883116883117, Precision:1.0, Recall:0.0, F1:0.0\n",
      "Activation Function:relu, Learning Rate: 0.01, Momentum:0.8, Epoch:100, Accuracy:0.6688311688311688, Precision:0.6688311688311688, Recall:1.0, F1:0.801556420233463\n",
      "Activation Function:relu, Learning Rate: 0.01, Momentum:0.8, Epoch:200, Accuracy:0.7662337662337663, Precision:0.7596899224806202, Recall:0.9514563106796117, F1:0.8448275862068966\n",
      "Activation Function:relu, Learning Rate: 0.001, Momentum:0.0, Epoch:50, Accuracy:0.7402597402597403, Precision:0.794392523364486, Recall:0.8252427184466019, F1:0.8095238095238095\n",
      "Activation Function:relu, Learning Rate: 0.001, Momentum:0.0, Epoch:100, Accuracy:0.33116883116883117, Precision:1.0, Recall:0.0, F1:0.0\n",
      "Activation Function:relu, Learning Rate: 0.001, Momentum:0.0, Epoch:200, Accuracy:0.7857142857142857, Precision:0.8017241379310345, Recall:0.9029126213592233, F1:0.8493150684931507\n",
      "Activation Function:relu, Learning Rate: 0.001, Momentum:0.2, Epoch:50, Accuracy:0.564935064935065, Precision:0.6836734693877551, Recall:0.6504854368932039, F1:0.6666666666666666\n",
      "Activation Function:relu, Learning Rate: 0.001, Momentum:0.2, Epoch:100, Accuracy:0.3246753246753247, Precision:0.0, Recall:0.0, F1:0.0\n",
      "Activation Function:relu, Learning Rate: 0.001, Momentum:0.2, Epoch:200, Accuracy:0.6688311688311688, Precision:0.6688311688311688, Recall:1.0, F1:0.801556420233463\n",
      "Activation Function:relu, Learning Rate: 0.001, Momentum:0.4, Epoch:50, Accuracy:0.33116883116883117, Precision:1.0, Recall:0.0, F1:0.0\n",
      "Activation Function:relu, Learning Rate: 0.001, Momentum:0.4, Epoch:100, Accuracy:0.6948051948051948, Precision:0.71875, Recall:0.8932038834951457, F1:0.7965367965367965\n",
      "Activation Function:relu, Learning Rate: 0.001, Momentum:0.4, Epoch:200, Accuracy:0.7857142857142857, Precision:0.8070175438596491, Recall:0.8932038834951457, F1:0.847926267281106\n",
      "Activation Function:relu, Learning Rate: 0.001, Momentum:0.6, Epoch:50, Accuracy:0.7987012987012987, Precision:0.8, Recall:0.9320388349514563, F1:0.8609865470852018\n",
      "Activation Function:relu, Learning Rate: 0.001, Momentum:0.6, Epoch:100, Accuracy:0.33116883116883117, Precision:1.0, Recall:0.0, F1:0.0\n",
      "Activation Function:relu, Learning Rate: 0.001, Momentum:0.6, Epoch:200, Accuracy:0.33116883116883117, Precision:1.0, Recall:0.0, F1:0.0\n",
      "Activation Function:relu, Learning Rate: 0.001, Momentum:0.8, Epoch:50, Accuracy:0.33116883116883117, Precision:1.0, Recall:0.0, F1:0.0\n",
      "Activation Function:relu, Learning Rate: 0.001, Momentum:0.8, Epoch:100, Accuracy:0.6688311688311688, Precision:0.6688311688311688, Recall:1.0, F1:0.801556420233463\n",
      "Activation Function:relu, Learning Rate: 0.001, Momentum:0.8, Epoch:200, Accuracy:0.7597402597402597, Precision:0.7894736842105263, Recall:0.8737864077669902, F1:0.8294930875576036\n"
     ]
    }
   ],
   "source": [
    "for func, rate,mo,e,accuracy,precision,recall,f1Score in results:\n",
    "    print(f\"Activation Function:{func}, Learning Rate: {rate}, Momentum:{mo}, Epoch:{e}, Accuracy:{accuracy}, Precision:{precision}, Recall:{recall}, F1:{f1Score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exporting result to excel for better viewing\n",
    "df = pd.DataFrame(results)\n",
    "df.head\n",
    "df.to_excel('result.xls')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Activation Function:sigmoid, Learning Rate: 0.1, Momentum:0.8, Epoch:100, Accuracy:0.8181818181818182, Precision:0.8378378378378378, Recall:0.9029126213592233, F1:0.869158878504673\n",
      "Activation Function:tanh, Learning Rate: 0.01, Momentum:0.8, Epoch:50, Accuracy:0.8116883116883117, Precision:0.8135593220338984, Recall:0.9320388349514563, F1:0.8687782805429866\n",
      "Activation Function:sigmoid, Learning Rate: 0.1, Momentum:0.4, Epoch:100, Accuracy:0.8116883116883117, Precision:0.8245614035087719, Recall:0.912621359223301, F1:0.8663594470046084\n",
      "Activation Function:sigmoid, Learning Rate: 0.1, Momentum:0.6, Epoch:100, Accuracy:0.8116883116883117, Precision:0.8303571428571429, Recall:0.9029126213592233, F1:0.8651162790697675\n",
      "Activation Function:sigmoid, Learning Rate: 0.1, Momentum:0.0, Epoch:50, Accuracy:0.8051948051948052, Precision:0.8067226890756303, Recall:0.9320388349514563, F1:0.8648648648648649\n"
     ]
    }
   ],
   "source": [
    "# result analysis\n",
    "sorted_res = sorted(results, key = lambda x: (x[7],x[4]),reverse=True)\n",
    "\n",
    "for j,k in enumerate(sorted_res[:5]):\n",
    "    print(f\"Activation Function:{k[0]}, Learning Rate: {k[1]}, Momentum:{k[2]}, Epoch:{k[3]}, Accuracy:{k[4]}, Precision:{k[5]}, Recall:{k[6]}, F1:{k[7]}\")\n",
    "    \n",
    "#sigmoid and tanh seems to outperform ReLU "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
